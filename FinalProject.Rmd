---
title: 'Open vs. closed innovation: using online network data to measure innovation'
author: "Benjamin Snow and Oliver Bott"
date: "12 December 2014"
linestretch: 2
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: true
    toc_depth: 2
  html_document:
    fig_caption: yes
    number_sections: no
bibliography:
- Packages.bib
- Main.bib
---

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# Set working directory. Change as needed
setwd('C:/Users/a6p/Desktop/Uni 2014/E1161 - Collaborative Research/GitHub Clone/Final_Project/')

require("devtools")
library(RCurl)
library(ggmap)
library(maptools)
library(dplyr)
library(reshape2)
library(maps)
library(stargazer)
library(rCharts)

# Load packages and create BibTeX file
# Note: must have repmis, rsdmx, httr, dplyr and rjson packages installed
PackagesUsed <- c("ggplot2", "repmis", "rsdmx", "httr", 
                  "dplyr", "rjson", "stargazer", "knitr", 
                  "car", "rCharts", "reshape2", "ggmap", 
                  "maps", "RCurl", "maptools", "Rcpp",
                  "rNVD3")

# Load PackagesUsed and create .bib BibTeX file
repmis::LoadandCite(PackagesUsed, file = "Packages.bib", install = FALSE)

```


__________________________________________________________________________________________________

> **Abstract:** This research project examines the potential benefit of using open knowledge data in the form of collaborative online network data as an innovation indicator. By doing so, this work critically assesses current innovation indicators, namely patent data, in the hope of offering new alternatives for measuring and understanding innovation. The stated research question is:  *To what extent can open innovation network data add to the measurement of innovation performance?* This study uses Github API follower data and patent data in 135 countries to compare the two, finding no correlation once controls are included in the model. However, several controls, including pollution and the relative importance of a city in its national context are both found to be correlated to both patent data and open innovation data, suggesting that both types of innovation bear fruit in similar circumstances. We suggest that, while the study does not conclusively determine a future metric for measuring open innovation or comparing types of innovation, it does suggest a potential expansion of the current field of measuring innovation, which could potentially more accurately represent innovation in the open technological age.

__________________________________________________________________________________________________

# Introduction

Policy makers worldwide have a profound interest in innovation for its significance for economic development and prosperity. @taylor2004 views innovation as "the driving force behind modern economic growth, relative industrial power, and competitive advantage" (p.222). Numerous studies, for example the Innovation Union Scoreboard[^IUS] and the OECD Science, Technology and Innovation Scoreboard[^STI], have attempted to measure and compare innovation performance on the national level.  However, until today most examinations of innovation have put their analytical emphasis on national level patent data, relying on this form of registering of proprietary data as a means of measuring innovation.  However, the use of pantent data has widely been criticized for its limited view of innovation, as patents are only filed as a means of protecting an idea for its exclusive commercial use. Many forms of innovation, with the key example being the opensource development of software, do not require or attempt government protection through patents, but would still in a digitalized society be considered as important forms of innovation.

Thus the academic literature until this point leaves largely unexplored other, more open measures of innovation disregarded. The relatively recent emergence of network-based research systems offer new and potentially more instructive metrics by which to measure innovation, compared to protected closed knowledge. Since various scholars called for the continuous improvement of innovation measurement [see for example @freeman2009], this work seeks to go beyond the widespread use of patent data to contribute to the refinement of innovation indicators, and the field as a whole. In the following section, the current state of the field will be examined. Current best practice of defining and measuring innovation will be discussed before highlighting how new open innovation can improve the measurement of innovation. Further, other factors influencing innovation intensity will be discussed, which will inform our later analysis. In the third section, our methodology will be stated, including the process of data gathering, selection and analysis. This will be followed by our main section, the analysis, in which we use descriptive and inferential statitics to answer our research question. In a first step, we analyze the relationship between open and closed innovation inthe form of collaborative online research platform use and patent intensity. In a second step, we look at the more fundamental drivers of innovation to establish whether there is an indirect relationship between the two variables of interest. Findings will be further discussed and summarized in the concluding section. Overall, we find that, despite our exploratory research and various data limitations, there is an indirect relationship between what we term open and closed innovation. The authors are confident that in the future, similar research incorporating open innovation data will help improve the measurement of innovation and thus enhance our understanding of innovation. 

# State of the Field

## Defining Innovation

Using a rather grand view in his understanding of innovation, @schumpeter1942 sees innovation as "a process of industrial mutation, that incessantly revolutionizes the economic structure from within". In a more understated characterization, @smith2005 defines innovation as "the creation of something qualitatively new, via processes of learning and knowledge building. It involves changing competences and capabilities, and producing qualitatively new performance outcomes" [@smith2005, 149]. While it is widely accepted that innovation can take many forms, e.g. product, process, marketing and proccess innovations, @frankelius2009, in his extensive literature review of innovation studies, criticizes the widespread underlying assumption that innovation is limited to technological innovation. While accepting @frankelius2009's critique of innovation as taking place outside of the technological realm, for the purpose of this study technological innovation, and specifically software innovation, will be the primary focus following relatively closely to @smith2005's definition.

## Measuring Innovation

The frequent technological focus when studying innovation can partly be explained by the difficulties associated with innovation's measurement. @smith2005 notes the measurement challenge, as innovation is by definition a novelty and thus commensurability is a demanding task. For these reasons innovation has traditionally though controversially been measured by looking either at its inputs, outputs, our throughputs. Attempting to measure innovation by inputs often focuses on resources, such as personnel and equipment allocated to research and development (R&D), which @freeman2009 notes is often overestimating innovation in R&D by including the routine with the novel. Put another way, the use of research and development funding to assess innovation assumes innovation to takes place linearly with enough resources, as if the doubling of the number of Austrian patent office workers would have somehow resulted in two Albert Einstein's coming from their ranks, rather that just one.  @freeman2009 compares this to output oriented measures, which are often based on what he concludes are the already inadequate measures such as GDP. As @freeman2009 suggests, GDP is an often cited imprecise statistical measure. However, building off of the first example, the use of output oriented measures the assumed result of innovation, economic growth, and not only assumes that the growth was based upon innovation, but seems to similarly assume that innovation creates value in a linear manner. A simple check of the wealth earned from various patents suggests this is not the case. Thus both input measures, such as R&D funding, and output measures, such as GDP, both either to not directly measure innovation, or do so in a manner so broad as to be unhelpful.

An indicator most often found in innovation research is patent data [see @taylor2004]. A patent is a "temporary legal monopoly granted by the government to an inventor for the commerical use of the invention [@taylor2004, 229). A patent constitutes a property right awarded when an invention is shown to be non-trivial, useful, and novel [@taylor2004, 230]. Patents were first used to measure demand-side determinants of innovation, and have been used in the analysis of innovation activity for over three decades [@taylor2004, 230). @taylor2004 uses patent data taken from 1963 to 1999 in six different industries and their future citation levels and uses Ordinary Least Squares (OLS) model to test what he terms the 'industry-innovation assumption'. The use of citations with patent data suggests a more nuanced examination of innovation using patent data that R&D fuding or GDP, as by using relative citation levels @taylor2004 was able to weight the relative importance of a patent.

## Limitations of Patent Data

Despite the usefulness of patent data, @taylor2004 finds several limitations. In addition to the 'classification problem' related to assigning a specific industries to patents, patents vary widely in significance, both technically and economically [@taylor2004, 231]. Most significantly for the purpose on this study, @taylor2004 as well as @pakes1980 find that "patents are a flawed measure particularly since not all new innovations are patented and since patents differ greatly in their economic impact” (@taylor2004, 378). @taylor2004 to some degree is able to take into account the relative importance of different patents by taking into account their future citation level, a relatively good proxy for importance. Still he is less able to tackle the problem of new innovations which are not patented, with patent levels subsequently underrepresenting innovation. Thus, while for some considerable time patents have been considered to be the most effective proxy with which to measure innovation, they themselves ascribe to the notion that there is room for improvement in the study of innovation. This study stands as an attempt to further this field, to attempt to diliniate innovation which would not appear in patent data, but is instead based upon open network data.

## Using Network Data as Innovation Indicator

Current developments in research indicate that "characteristics that were important last century may well no longer be so relevant today and indeed may even be positively misleading" [@freeman2009, 3]. A shift away from the belief that innovation only occurs in professional R&D labs has occured, a change towards what @freeman2009 calls "research without frontiers" (p.13). Even though networks and research collaborations become increasingly important, there have been relatively few studies focusing on network data [see @breschi2005]. Even where research networks have been analyzed, the focus is too often on economically useful knowledge [see @acs2002]. Other studies focusing on research networks focus on other protected collaborative networks [see @ponds2010]. In an exception to this standard, @senghore2014 attempt to answer whether social network statistics act as indicators of innovation performance within a network, and which statistics could predict innovation performance. Using @Gnyawali2013's use models on cluster and network effects to analyze multipartite social networks at mass collaboration events, gathering their data from NASA's International Space Apps Challenge. They use graph theory models constructed from affiliation networks finding (preliminarily) that distributions likely correlate to key aspects [@senghore2014].  

Since @freeman2009, among others, calls for the continuous improvement of innovation measurement, this work seeks to contribute to the refinement of innovation indicators. The purpose of this study is to explore the conceptual and statistical viability of a new metric by which we can measure innovation. 

## Fundamental Drivers of Innovation

While most previous studies of measuring innovation, as seen above, focus on the inputs (R&D) or outputs (GDP) of innovation, which this study attempts to reconsider, other research has attempted to define what actually drives or fosters innovation. While not the main focus of this study, which looks at measurement rather than impetus, an examination of what is considered plausible as a cause of innovation seems highly relevant.  

When considering innovation drivers, a common culprit is creativity. While this may seem somewhat redundant, as innovation and creativity often in common langauge are used synonymously, for academic purposes innovation is the output of, and requires, creativity, but must be taken seperately.  However, the importance of creativity to innovation, and as a contributing predictor or cause of innovation has often been examined. @Florida2006, when discussing the creative economy, cites the importance of creativity not only in the science and technological fields, but the wider economy as as a whole. He emphasizes the importance of schools and universities fostering creativity, and additionally notes the importance of geography and proximity to creative innovation, naming major global cities and imploring readers to move to one of these hubs, as the innovative as well as economic divide between these hubs and the rest of the world grows wider. To attract creative talent, deemend necessary for innovation, cities need to have certain characteristics [@Florida2006; @johnson2014].  

To study not only the direct relationship between patent and open innovation requires also taking into account other variables which either must be controlled for when evaluating both forms of innovation, or which could explain one or another form of innovation in a specific locale, to explain what attributes of a location predict or explain innovation rather than simply measuring it. Many studies have attempted to evaluate different attributes of innovative regions, with policymakers wishing to find the elusive set of policies or conditions under which innovation flourishes.  

@porter1991 originally hypothesized that relationship to the environment, and specifically environmental regulation could have a positive effect on innovation, as it forces the hand of domestic firms to be more innovative than their foreign counterparts, to remain competitive despite the increased regulation. However, this initial hypothesis was not found in the evidence when tested by @jaffe1997environmental, finding little evidence that industries become more inventive due to compliance costs. Wider examinations of the specific environmental conditions of a locale, its pollution level or amount of greenspace, for instance, affect peoples level of innovation in these areas, or whether high mobility of labor allows innovators to selectively choose where they innovate. Along this line of thinking, @Florida2006 and @joohnson2014 mentioned previously in relation to creativity and innovation, suggests that as creativity is a flow rather than a stock, and requires an open system and longterm development, it can only take place in places where people can easily get to, lead the lives they want, and express themselves.  

Past environmental conditions, labor conditions have long been studied as potentially relevant to the rate of innovation.  Most often oversimplified as a cause and effect statement "Does technology create or destroy jobs" in which innovation in technology is the culbrit of economic disruptions. However, @pianta2005innovation instead examines how innovation and employment effect each other when composition of skills and wages, and employment are taken into account, but often looks at innovation on the organizational, rather than the societal, level. This is why this study also takes into account variables that can explain innovation intensity in a given location, namely the GDP, total urban population, urban greenspace available, pollution levels and relative importance of a city in relation to its national context. Empirical findings in the literature suggest that these factors can affect the attraction and retaining of creative talent fundamental for any form of innovation activity.

## Research Question

In light of the above mentioned state of innovation research we plan to examine the following research question: *To what extent can open innovation network data add to the measurement of innovation performance?*  

Exploiting technological advances related to the increasing use of the internet and open research platforms like GitHub, we plan to explore whether open knowledge networks can help refine currently limited innovation performance measurements.


# Methodology

## Data Gathering

To examine open network data against patent data, this study relies on two key data sources and uses the statistical tool *R* [@CiteR] for the data analysis. We take city-level data of 132 cities overall, ranging from sixteen different countries.  

**API network data**  

The first data set is obtained by using the Application Programming Interface (API) data for open networks. To examine open innovation, data is obtained from the the git repository web-based hosting service GitHub[^GIT]. Its use of source code management makes it a commonly used software development collaboration tool. Since most of the repositories are openly accessible one can use API tools to track the popularity of contributors through a process called following. The *R* [@CiteR] packages *httr* [@R-httr], *dplyr* [@R-dplyr] and *rjson* [@R-rjson] allow for compiling data on the follower counts and locations associated with different users and online reponsitories.  

**Closed innovation OECD patent data**  

For closed innovation we use city-level patent data, taken from the Organization for Economic Co-operation and Development[^OECD]. Patent Cooperation Treaty (PCT) patent data are used to track internationally patented inventions. The *R* [@CiteR] package *rsdmx* [@R-rsdmx] is necessary for obtaining the OECD dataset.  As we are interested in patent data, we work with data indicating the PCT patent applications per 10,000 inhabitants. From the same database, we also use GDP per capita data and environmental data, as other variables thought potentially relevant in explaining differences in innovation.  

To allow for reproducibility of this research, the code for gathering and cleaning the data is stored in a separate .R file and can be accessed [here](https://raw.githubusercontent.com/oliverbott/Final_Project/master/Data/Data_Gathering_Final.Rmd). Packages to clean, analyze and visualize the data include *R-car* [@R-car], *R-ggmap* [@R-ggmap], *ggplot2* [@R-ggplot2], *maps* [@R-maps], *maptools* [@R-maptools], *Rcpp* [@R-Rcpp], *rCharts* [@R-rCharts], *RCurl* [@R-RCurl], *repmis* [@R-repmis], *reshape2* [@R-reshape2] and *stargazer* [@R-stargazer].


```{r, include=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# Load Dataset.csv from repository
library(RCurl)

# Set SSL certs globally
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))

# Create dynamic link to Dataset.csv created through the Data_Gathering.R
x <- getURL('https://raw.githubusercontent.com/oliverbott/Final_Project/master/Data/Dataset.csv')
dataset <- read.csv(text = x)

# Clean dataset
dataset$row.names <- NULL
dataset$X <- NULL

# Change column names
colnames(dataset) <- c("METRO_ID" , "Patents" , "GDP" , "Population", "Greenspace", "Employment" , "Pollution" , "lon" , "lat" , "AnyFollowing" , "1" , "10" , "20" , "30" , "40" , "50" , "60" , "70" , "80" , "90" , "100" , "US" , "DE" , "FR" , "JP" , "Users")
```

## Data Sources

As can be seen in Table 1, the analysis is based on cross-sectional data with varying time frames. There are several limitations to the data used in this study. First, the time discrepency between different aspects of the data used, which range from 2005 to 2014, reflect an obvious data comparability constraint. The GitHub user data is taken from December 2014. Secondly, in this analysis for data availability and access reasons, there are some prominent innovation hubs excluded, including San Fransisco and New York. Any found significance will need to take this into account. Last, and perhaps most significantly, when comparing the two measures of innovation, it should be noted that patent data reflects innovation across all types of sectors, whereas Github data mainly reflects innovation within the software technology domain.  

+ only cross-sectional data: no time trend, limited validity
+ diffusion of GitHub very low (but growing steadily)
+ language issues
+ users might not indicate their place of residency

However, in defense of the dataset employed - with regard to the time discrepancy issue, many of the variables which are from different times would likely have limited change in a decade, for instance greenspace or industrialization are not aspects of a city which would change drastically. In regards to the exclusion of a few major tech spaces, which non-inclusion does not help the dataset, the use of over 130 cities should allow trends to be seen despite imperfect data. While the exclusion of some important innovation hubs like New York and San Fransisco should be taken into account, it seems implicitly that the studies finding would actually serve to provide better more general trends and relationships, by excluding tech havens and rather looking more broadly at the pace of innovation in most of the world.

                         Table 1: Data sources and explanations.

```{r Table 1: Data sources and explanations, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
library(knitr)

# Create table with info on variables
Variables <- c('Patents', 'GDP', 'Population', 'Greenspace', 
               'Employment', 'Pollution', 'Users')
Explanation <- c('PCT patents per 10,000 population', 'GDP per capita', 
                 'Total urban population', 'Green area per capita in square metres', 
                 'Employment of metropolitan area as % of national value', 
                 'Annual average of pop exposure to air pollution PM2,5 in µg/m³', 
                 'GitHub users with >20 followers per 10,000 population')
Year <- c('2008', '2008','2008','2008','2008',
          '2005', '2014')
Source <- c('OECD', 'OECD', 'OECD', 'OECD', 'OECD', 
            'OECD', 'GitHub')


# Combine
limtab <- data.frame(Variables, Explanation, Year, Source)

knitr::kable(limtab)

```


## Data Selection

Several potential explanatory variables are collected besides the patent and GitHub data. These variables were selected as they were thought to potentially show cause for why innovation, be it open or closed, occurs in a certain city, but needed to be variables that would not introduce endogeneity to the model. 

**Greenspace**: The Greenspace indicator is deemed potentially relevant in that with a choice of city to innovate in (assuming some level of geographic labor flexibility) there might be a recreational value necessary for attracting talent. Put another way, green cities could attract innovators.  

**Pollution**: The Pollution indicator is taken both as a broad proxy for the urban environmental conditions and also the level of industrialization (leaving aside a discussion of to what degree pollution is from industry vs cars), that it seemed worth exploring whether a certain level of pollution discouraged talent attraction of innovators on the city-level.

**Employment**: The Employment indicator is taken largely as an indication of that city´s significance within its national context. Understanding whether a city would likely be viewed as the most prominent or significant, and whether this effects innovation, or whether innovation takes place in smaller provincial cities, is worther understanding.  Additionally, seeing if the type of innovation (open vs. closed) depends on the significance of the city is viewed as relevant.  

**GDP**: A GDP indicator explores whether the size of the economy, or wealth generally, is related to innovation on the city-level, and if it is indicator of one type of innovation over another.  

**Population**: A Population variable explores whether there is a necessary city size threshold which corresponds to innovation, and also is taken for controlling for across cities, to find patent data or GitHub data per a number of people in a city.  

**GitHub user follower counts**: The number of GitHub users with a certain follower count acts as our main variable of interest. To determine which follower range can be deemed as an indicator for innovative activities,  we compile follower data in various categories ranging from users with 1-9, 10-19 up to 90-99 and over 100 followers (per 10,000 population). We choose GitHub users with more than 20 followers as our main indicator of high collaboration and innovative activity, as the threshold of 20 represents a drastic decline in user counts as can be seen in Figure 1.  


```{r Follower Cutoff Selection, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
# Load .csv from GitHub repository
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))

# Create dynamic link to Dataset.csv created through the Data_Gathering.R
x <- getURL('https://raw.githubusercontent.com/oliverbott/Final_Project/9c08cb04289524812f7f2a94a00bd5d89b7fa7de/Data/Dataset.csv')
datasetold <- read.csv(text = x)

# For this task we get rid of the other variables
datasetold$X <- NULL
datasetold$Patents <- NULL
datasetold$GDP <- NULL
datasetold$Population <- NULL
datasetold$Pollution <- NULL
datasetold$Greenspace <- NULL
datasetold$Employment <- NULL
datasetold$lon <- NULL
datasetold$lat <- NULL
datasetold$zeroFollowers <- NULL

new <- datasetold
new_2 <- reshape(new, 
                 varying = c("US", "DE", "FR", "JP"), 
                 v.names = "value",
                 timevar = "Country", 
                 times = c("US", "DE", "FR", "JP"), 
                 new.row.names = 1:1000,
                 direction = "long")

new_2 <- subset(new_2, value>0)
new_2$id <- NULL 
new_2$value <- NULL
new_2$Country <- as.factor(new_2$Country)
x_2 <- split(new_2, new_2$Country)
x_3 <- lapply(x_2, function (x) sapply(x, mean))
x_3 <- data.frame(x_3)
x_3 <- na.omit(x_3)

df <- reshape(x_3, 
                 varying = c("US", "DE", "FR", "JP"), 
                 v.names = "value",
                 timevar = "Country", 
                 times = c("US", "DE", "FR", "JP"), 
                 new.row.names = 1:1000,
                 direction = "long")
variable <- c(1,10,20,30,40,50,60,70,80,90,100, 
              1,10,20,30,40,50,60,70,80,90,100,
              1,10,20,30,40,50,60,70,80,90,100,
              1,10,20,30,40,50,60,70,80,90,100)
df <- data.frame(df, variable)
df$id <- NULL 
df$variable <- as.factor(df$variable)

# Set color scheme
library(RColorBrewer)
myColours <- brewer.pal(6,"Set3")

my.settings <- list(
  superpose.polygon=list(col=myColours[3:6], border="transparent"),
  strip.background=list(col=myColours[6]),
  strip.border=list(col="black")
)

require(lattice)
barchart(value ~ variable, groups=Country, df, auto.key = list(columns = 4), 
         main="Follower counts in different countries", xlab="Follower category", 
         ylab="Frequency", par.settings = my.settings, scales=list(alternating=1),
         uto.key=list(space="top", columns=4, 
                      points=FALSE, rectangles=TRUE,
                      title="District", cex.title=1),
         par.strip.text=list(col="white", font=2),)

```

# Analysis

## Descriptive Statistics

The summary statistics in Table 2 show wide ranging distributions of the observations in the data set. The *car* package [@R-car] is used to examine the relationship, distribution, and normality of all variables included in the model, to understand which regression model would be most appropriate. The distribution of many variables are highly skewed (see Figure 1). The GitHub based variable 'Users', our main variable of interest, is skewed to the right, as do nearly all of the observed variables, excluding Pollution, GDP and Patents, which come closer to a normal distribution. It seems as if already in the scatterplot a weak correlation between Patents and Users can be observed. To normalize for the skewed distributions, the log of the variables is deemed necessary to increase the explanatory power of our inferential statistics.  


```{r Summary Statistics of selected variables, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
# Descriptive statistics
library(stargazer)

sumdat <- subset(dataset, select = -c(1,8:9,22:25) )

colnames(sumdat) <- c("Patents" , "GDP" , "Population", "Greenspace", "Employment" , "Pollution" , ">0 Followers" , "1-9 Followers" , "10-19 Followers" , "20-29 Followers" , "30-39 Followers" , "40-49 Followers" , "50-59 Followers" , "60-69 Followers" , "70-79 Followers" , "80-89 Followers" , "90-99 Followers" , ">100 Followers" , ">20 Followers")

stargazer(sumdat[,], summary=TRUE,
  title = 'Summary statistics',
  digits = 2, type ='latex', header=FALSE)

```


```{r Scatterplot matrix of selected variables, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
# Create scatterplot matrix of variables
require("car")

scatmat <- subset(dataset, select = -c(1,8:9,11:25) )

car::scatterplotMatrix(scatmat[,], 
                       main="Scatterplot matrix")

```


## Inferential Statistics

To determine which regression model to choose for the inferential statistics, we use a residual plot. The residual plot between Patents and Users (see Figure 2) depicts a relatively random pattern, which indicates that a linear regression model provides a decent fit to the inferential statistics of the data set.  

```{r, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}

# For log delete 0 follower categories: new datasetlog
datasetlog <- dataset
datasetlog <- datasetlog[-c(45, 59, 62, 63, 73, 81, 90, 116, 121), ]

datasetlog2 <- dataset
datasetlog2 <- datasetlog2[-c(45, 62, 90), ]

# Create residual plot for log(Patents)
patfol.lm = lm(log(Patents) ~ log(Users)
               , data = datasetlog)
patfol.res = resid(patfol.lm)

plot(datasetlog$Users, patfol.res,
     ylab="Residuals", xlab="High Followers",
     main="Patents")
abline(0, 0)

```


```{r Regression Preparation, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# Regression table with stargazer

# Create country interaction
datasetlog$USfol <- datasetlog$Users*datasetlog$US
datasetlog$DEfol <- datasetlog$Users*datasetlog$DE
datasetlog$FRfol <- datasetlog$Users*datasetlog$FR
datasetlog$JPfol <- datasetlog$Users*datasetlog$JP

# Create regression models with Patents as dependent variable
P1 <- lm(log(Patents) ~ log(Users), data = datasetlog)
P2 <- lm(log(Patents) ~ log(Users) + log(GDP) + log(Population) + 
           log(Greenspace) + log(Employment) + log(Pollution), data = datasetlog)
P3 <- lm(log(Patents) ~ log(Users) + log(GDP) + log(Population) + 
           log(Greenspace) + log(Employment) + log(Pollution), data = datasetlog)

labelsP <- c('Over 20 Followers', 'GDP', 'Population', 'Greenspace', 'Employment', 'Pollution', '(Intercept)')

# Create regression models with User numbers as dependent variable
F1 <- lm(log(Users) ~ log(Patents), data = datasetlog)
F2 <- lm(log(Users) ~ log(Patents) + log(GDP) + log(Population) + 
           log(Greenspace) + log(Employment) + log(Pollution), data = datasetlog)
F3 <- lm(log(Users) ~ log(Patents) + log(GDP) + log(Population) + 
           log(Greenspace) + log(Employment) + log(Pollution) + US + DE + FR + JP, data = datasetlog)

labelsF <- c('Patents', 'GDP', 'Population', 'Greenspace', 'Employment', 'Pollution', 'US' , 'DE' , 'FR' , 'JP', '(Intercept)')

# Create regression models with any Following numbers as dependent variable
D1 <- lm(log(AnyFollowing) ~ log(Patents), data = datasetlog2)
D2 <- lm(log(AnyFollowing) ~ log(Patents) + log(GDP) + log(Population) + log(Greenspace) + log(Employment) + log(Pollution), data = datasetlog2)
D3 <- lm(log(AnyFollowing) ~ log(Patents) + log(GDP) + log(Population) + log(Greenspace) + log(Employment) + log(Pollution) + US + DE + FR + JP, data = datasetlog2)

labelsD <- c('Users', 'GDP', 'Population', 'Greenspace', 'Employment', 'Pollution', 'US' , 'DE' , 'FR' , 'JP', '(Intercept)')
```

This study uses an ordinary least squares (OLS) model to examine the relationship between patent and highly followed open data sources. The first regression model includes the open innovation indicator *U* as the GitHub users with more than 20 followers variable expected in a given city *i*, and can be viewed as:

$$   logU_{l} = {\beta}_0 +{\beta}_1 logP_{l} + {\beta}_2 logGDP_{l} + {\beta}_3 logPop_{l} + {\beta}_4 logG_{l} + {\beta}_4 logE_{l} + {\beta}_4 logPol_{l} + {\epsilon}_{l}$$  


```{r, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
stargazer::stargazer(F1, F2, F3, covariate.labels = labelsF,
  title = 'Regression Estimates of GitHub user couts',
  digits = 2, type ='latex', single.row=TRUE, header=FALSE)
```

As can be seen in Table 3, the variable User is strongly positively correlated with the Patent variable (at a significance level of p<0.01). Without including controls, a 1% increase in patents corresponds to a 0.37% increase in GitHub users with over 20 followers. However, the correlation becomes much smaller and insignificant when adding control variables. The GDP (at a significance level of p<0.01) and relative significance of a city in its national context, represented by the Employment variable, (at a significance level of p<0.1) are positively correlated with GitHub users, while the pollution levels negatively correlate with our User variable (at a significance level of p<0.05). The urban greenspace and total population size of the city do not seem to have a correlation with GitHub users.  

When adding country dummies, it becomes clear that both the United States and France seem to have more GitHub users than other countries in the sample. No effect can be seen for German and Japanese cities. The dummies must be interpreted with care, however, since the sample sizes for cities in these countries are very small, hence the relatively large standard error. The adjusted R squared value indicates that, for our final specification of the first model, about 30% of the variation in users in our sample is explained through the model. The weak relationship between GitHub users and patents also becomes evident in the scatterplot in Figure 4, where we can witness a wide dispersion between the two variables. The distribution of the data points indicates that some cities have relatively many GitHub users with more than 20 followers while some cities have close to zero users per 10,000 population.  


```{r Scatterplot, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
# Simple Scatterplot
attach(datasetlog)
plot(Users, Patents, main="Scatterplot for GitHub users and patents", 
    xlab="GitHub users with >20 followers ", ylab="Patents", pch=19)
abline(lm(Patents~Users), col="red") # regression line (y~x) 
```

Although there does not seem to be a direct relationship between patent and GitHub user data, further inferential statistical analysis attempts to find the common predictor or cause of innovation in both patent and open data. Our second model hence uses patents as the dependent variable *P* and is expressed below using similar notation and logic as stated above:  

$$   logP_{i} = {\beta}_0 +{\beta}_1 logU_{i} + {\beta}_2 logGDP_{i} + {\beta}_3 logPop_{i} + {\beta}_4 logG_{i} + {\beta}_5 logE_{i} + {\beta}_6 logPol_{i} + {\epsilon}_{i}$$  

```{r, echo=FALSE, results='asis', warning=FALSE, error=FALSE, message=FALSE}
stargazer::stargazer(P1, P2, P3, covariate.labels = labelsP,
  title = 'Regression Estimates of Patent Activity',
  digits = 2, type ='latex', single.row=TRUE, header=FALSE)
```

Similar to the first model, the regression output for our second model (see Table 4) demonstrates a positive relationship between patent data and GitHub users (at a significance level of p<0.01), but only when no controsl are added. In the full model specification, again GDP and relative importance of a city in its national context positive correlate with Patents. Interestingly, however, the pollution level is also positively correlated to Patents (at a significance level of p<0.05). The adjusted R squared value indicates that, for our final specification of the second model, about 27% of the variation in patents in our sample is explained through the model. Our analysis does not allow any statements as to the causal relationship of the variables in question, as we cannot eliminate potential endogeneity issues, e.g. through omitted variable bias, reversed causation or selection issues. This is why in our analysis we only speak of correlation but not to what extent one variable has an effect on another.   

The inferential statistics do not support our initial hypothesis that there is a direct link between open and closed innovation. Still we can see from the analysis that both patents and GitHub users innovative activities require similar conditions, which indicates that there is an indirect link between the two variables of interest. These findings support the claims brought forward by @jaffe1997environmental, @Florida2006 and @johnson2014, who argue that cities need certain characteristics to attract creative talent and hence to become creative and innovative hubs. This is an important finding of our study, as it highlights the framework conditions for attracting and retaining talent at a certain locale, especially for such mobile talents working in programming and broader software developments [@Florida2006]. Still, when interpreting our findings, one needs to aware that there might be other unaccounted for variables to contribute to patents and user couts but are not currently accounted for in the model.  

# Conclusion

The findings endorse the implicit hypothesis of the study that open data sources seem to show innovation in a similar but perhaps distinct manner to patent data and could hence enrich the measurement of innovation. While no direct correlation was found between patent data and GitHub user data, it remains an open question whether this means that follower data is a poor measurement for innovation, or whether potentially they measure a different type of innovation. It seems plausible that GitHub data offers a glimps into the 'throughput' of open innovation (in the form of collaboration) rather than the 'output' which patent data reflects (in the form of commercialization of knowledge). It could be that patent data better takes into account the exact moment and type of innovation, as it is tied to the patent application itself, whereas someone could choose to follow someone based upon other reasoning than their level of innovation.  

Interestingly, as the strongest relationships were found not between patent and follower data, but rather between these two variables and the city related control variables, that many of the conditions which foster both open and closed innovation, in this case GDP and city importance, both positively affect the drive of innovation in a city. Due to these parallels, it seems plausible that policy makers could institute similar reforms to positively affect both. This research was done in response to claims made by scholars such as @taylor2004 and @freeman2009who call for a rethinking of how we measure innovation. Despite its obvious limitations, there is a strong need for more innovative ways of approaching the study of innovation itself.  

Clearly our research approach relying solely on GitHub user data as a measure of open innovation is far from exhaustive. Further research could include other, similarly impotant collaborative research plattforms. The fast diffusion of such research platforms could mean that similar analytical approaches could lead to much different findings. Other studies could also include more control variables to account for other factors influencing both patents and collaborative network activities, which due to limited data availability could not be analyzed in this research project. Furthermore, a time series or panel data analysis could examine time trends and hence significantly increase the validity of the research findings. 

[^IUS]: For the latest edition see [http://ec.europa.eu/enterprise/policies/innovation/policy/innovation-scoreboard/index_en.htm](http://ec.europa.eu/enterprise/policies/innovation/policy/innovation-scoreboard/index_en.htm).
[^STI]: For the latest edition see [http://www.oecd.org/sti/scoreboard.htm](http://www.oecd.org/sti/scoreboard.htm).
[^OECD]: Online accessible on [http://stats.oecd.org](http://stats.oecd.org).
[^GIT]: Online accessilbe on [https://github.com/](https://github.com/).

# References

---
title: "Data gathering and cleaning"
author: "Oliver Bott and Benjamin Snow"
date: "Thursday, November 27, 2014"
output: html_document
---

```{r}
# Set working directory
setwd('C:/Users/a6p/Desktop/Uni 2014/E1161 - Collaborative Research/GitHub Clone/Final_Project/Data/')
```

```{r}
# Load OECD data and locations

require("devtools")
library("rsdmx")


# Pull OECD city patent data
dataURL <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/AT001+AT002+AT003+BE001+BE002+BE003+BE005+DE001+DE002+DE003+DE004+DE005+DE006+DE007+DE008+DE009+DE010+DE011+DE012+DE013+DE015+DE027+DE033+DE034+DE035+DE501+DE502+DE507+DK001+EE001+ES001+ES002+ES003+ES004+ES005+ES006+ES008+ES019+FI001+FR001+FR003+FR004+FR006+FR007+FR008+FR009+FR010+FR013+FR026+FR032+FR203+FR205+FR215+IT001+IT002+IT003+IT004+IT005+IT006+IT007+IT008+IT009+IT010+IT011+JP026+JP030+JP031+JP034+JP036+JP038+JP050+JP051+JP052+JP053+JP054+MEX19+MEX38+NL001+NL002+NL003+NL004+NO001+PT001+PT002+SE001+SE002+SE003+US003+US012+US014+US033+US035+US038+US044+US045+US048+US055+US060+US065+US069+US077+US081+US097+US103+US106+US107+US114+US115+US117+US122+US124+US125+US141+US147+US149+US155+US160+US161+US170+US178+US180+US181+US195+US196+US202+US209+US213+US223+US234+US237+US242+US250+US252+US259.PCT_INTENSITY?startTime=2008&endTime=2012"

sdmx <- readSDMX(dataURL)
city_pat <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_pat$VAR <- NULL # Delete columns
city_pat$attrs.df <- NULL

colnames(city_pat) <- c("METRO_ID" , "Year" , "Patents") # Rename columns

# Pull OECD GDP per capita data
dataURL2 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/AT001+AT002+AT003+BE001+BE002+BE003+BE005+DE001+DE002+DE003+DE004+DE005+DE006+DE007+DE008+DE009+DE010+DE011+DE012+DE013+DE015+DE027+DE033+DE034+DE035+DE501+DE502+DE507+DK001+EE001+ES001+ES002+ES003+ES004+ES005+ES006+ES008+ES019+FI001+FR001+FR003+FR004+FR006+FR007+FR008+FR009+FR010+FR013+FR026+FR032+FR203+FR205+FR215+IT001+IT002+IT003+IT004+IT005+IT006+IT007+IT008+IT009+IT010+IT011+JP026+JP030+JP031+JP034+JP036+JP038+JP050+JP051+JP052+JP053+JP054+MEX19+MEX38+NL001+NL002+NL003+NL004+NO001+PT001+PT002+SE001+SE002+SE003+US003+US012+US014+US033+US035+US038+US044+US045+US048+US055+US060+US065+US069+US077+US081+US097+US103+US106+US107+US114+US115+US117+US122+US124+US125+US141+US147+US149+US155+US160+US161+US170+US178+US180+US181+US195+US196+US202+US209+US213+US223+US234+US237+US242+US250+US252+US259.GDP_PC?startTime=2008&endTime=2008"

sdmx <- readSDMX(dataURL2)
city_gdp <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_gdp$VAR <- NULL # Delete columns
city_gdp$attrs.df <- NULL

colnames(city_gdp) <- c("METRO_ID" , "Year" , "GDP") # Rename columns

# Pull OECD population data
dataURL3 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/AT001+AT002+AT003+BE001+BE002+BE003+BE005+DE001+DE002+DE003+DE004+DE005+DE006+DE007+DE008+DE009+DE010+DE011+DE012+DE013+DE015+DE027+DE033+DE034+DE035+DE501+DE502+DE507+DK001+EE001+ES001+ES002+ES003+ES004+ES005+ES006+ES008+ES019+FI001+FR001+FR003+FR004+FR006+FR007+FR008+FR009+FR010+FR013+FR026+FR032+FR203+FR205+FR215+IT001+IT002+IT003+IT004+IT005+IT006+IT007+IT008+IT009+IT010+IT011+JP026+JP030+JP031+JP034+JP036+JP038+JP050+JP051+JP052+JP053+JP054+MEX19+MEX38+NL001+NL002+NL003+NL004+NO001+PT001+PT002+SE001+SE002+SE003+US003+US012+US014+US033+US035+US038+US044+US045+US048+US055+US060+US065+US069+US077+US081+US097+US103+US106+US107+US114+US115+US117+US122+US124+US125+US141+US147+US149+US155+US160+US161+US170+US178+US180+US181+US195+US196+US202+US209+US213+US223+US234+US237+US242+US250+US252+US259.POP?startTime=2008&endTime=2008"

sdmx <- readSDMX(dataURL3)
city_pop <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_pop$VAR <- NULL # Delete columns
city_pop$attrs.df <- NULL

colnames(city_pop) <- c("METRO_ID" , "Year" , "Population") # Rename columns


# Pull OECD urban pollution (Estimated population exposure to air pollution PM2.5 expressed in mirco gram per cubic metre, annual average)
dataURL4 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/AT001+AT002+AT003+BE001+BE002+BE003+BE005+DE001+DE002+DE003+DE004+DE005+DE006+DE007+DE008+DE009+DE010+DE011+DE012+DE013+DE015+DE027+DE033+DE034+DE035+DE501+DE502+DE507+DK001+EE001+ES001+ES002+ES003+ES004+ES005+ES006+ES008+ES019+FI001+FR001+FR003+FR004+FR006+FR007+FR008+FR009+FR010+FR013+FR026+FR032+FR203+FR205+FR215+IT001+IT002+IT003+IT004+IT005+IT006+IT007+IT008+IT009+IT010+IT011+JP026+JP030+JP031+JP034+JP036+JP038+JP050+JP051+JP052+JP053+JP054+MEX19+MEX38+NL001+NL002+NL003+NL004+NO001+PT001+PT002+SE001+SE002+SE003+US003+US012+US014+US033+US035+US038+US044+US045+US048+US055+US060+US065+US069+US077+US081+US097+US103+US106+US107+US114+US115+US117+US122+US124+US125+US141+US147+US149+US155+US160+US161+US170+US178+US180+US181+US195+US196+US202+US209+US213+US223+US234+US237+US242+US250+US252+US259.AIR_POLLUTION?startTime=2005&endTime=2005"

sdmx <- readSDMX(dataURL4)
city_pol <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_pol$VAR <- NULL # Delete columns
city_pol$attrs.df <- NULL
city_pol$obsTime <- NULL

colnames(city_pol) <- c("METRO_ID" , "Pollution") # Rename columns

# Pull OECD Greenspace (Estimated population exposure to air pollution PM2.5 expressed in mirco gram per cubic metre, annual average)
dataURL5 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/AT001+AT002+AT003+BE001+BE002+BE003+BE005+DE001+DE002+DE003+DE004+DE005+DE006+DE007+DE008+DE009+DE010+DE011+DE012+DE013+DE015+DE027+DE033+DE034+DE035+DE501+DE502+DE507+DK001+EE001+ES001+ES002+ES003+ES004+ES005+ES006+ES008+ES019+FI001+FR001+FR003+FR004+FR006+FR007+FR008+FR009+FR010+FR013+FR026+FR032+FR203+FR205+FR215+IT001+IT002+IT003+IT004+IT005+IT006+IT007+IT008+IT009+IT010+IT011+JP026+JP030+JP031+JP034+JP036+JP038+JP050+JP051+JP052+JP053+JP054+MEX19+MEX38+NL001+NL002+NL003+NL004+NO001+PT001+PT002+SE001+SE002+SE003+US003+US012+US014+US033+US035+US038+US044+US045+US048+US055+US060+US065+US069+US077+US081+US097+US103+US106+US107+US114+US115+US117+US122+US124+US125+US141+US147+US149+US155+US160+US161+US170+US178+US180+US181+US195+US196+US202+US209+US213+US223+US234+US237+US242+US250+US252+US259.GREEN_AREA_PC?startTime=2008&endTime=2008"

sdmx <- readSDMX(dataURL5)
city_green <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_green$VAR <- NULL # Delete columns
city_green$attrs.df <- NULL

colnames(city_green) <- c("METRO_ID" , "Year" , "Greenspace") # Rename columns

# Pull OECD city employment of metropolitan area as % of national value 2008
dataURL6 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/AT001+AT002+AT003+BE001+BE002+BE003+BE005+DE001+DE002+DE003+DE004+DE005+DE006+DE007+DE008+DE009+DE010+DE011+DE012+DE013+DE015+DE027+DE033+DE034+DE035+DE501+DE502+DE507+DK001+EE001+ES001+ES002+ES003+ES004+ES005+ES006+ES008+ES019+FI001+FR001+FR003+FR004+FR006+FR007+FR008+FR009+FR010+FR013+FR026+FR032+FR203+FR205+FR215+IT001+IT002+IT003+IT004+IT005+IT006+IT007+IT008+IT009+IT010+IT011+JP026+JP030+JP031+JP034+JP036+JP038+JP050+JP051+JP052+JP053+JP054+MEX19+MEX38+NL001+NL002+NL003+NL004+NO001+PT001+PT002+SE001+SE002+SE003+US003+US012+US014+US033+US035+US038+US044+US045+US048+US055+US060+US065+US069+US077+US081+US097+US103+US106+US107+US114+US115+US117+US122+US124+US125+US141+US147+US149+US155+US160+US161+US170+US178+US180+US181+US195+US196+US202+US209+US213+US223+US234+US237+US242+US250+US252+US259.EMP_SHARE?startTime=2008&endTime=2008"

sdmx <- readSDMX(dataURL6)
city_emp <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_emp$VAR <- NULL # Delete columns
city_emp$attrs.df <- NULL

colnames(city_emp) <- c("METRO_ID" , "Year" , "Employment") # Rename columns

# Merge all OECD citydata sets
oecd_pat_gdp <- merge(city_pat , city_gdp , by=c("METRO_ID" , "Year"))
oecd_pat_gdp_pop <- merge(oecd_pat_gdp , city_pop , by=c("METRO_ID" , "Year"))
oecd_pat_gdp_pop_green <- merge(oecd_pat_gdp_pop , city_green , by=c("METRO_ID" , "Year"))
oecd_pat_gdp_pop_green_emp <- merge(oecd_pat_gdp_pop_green , city_emp , by=c("METRO_ID" , "Year"))
oecd <- merge(oecd_pat_gdp_pop_green_emp , city_pol , by=c("METRO_ID"))


# Clean city table, insert city and country names
oecd$Year <- NULL

oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "AT001" , "Vienna")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "AT002" , "Graz")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "AT003" , "Linz")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "BE001" , "Brussels")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "BE002" , "Antwerp")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "BE003" , "Ghent")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "BE005" , "Liege")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE001" , "Berlin")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE002" , "Hamburg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE003" , "Munich")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE004" , "Cologne")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE005" , "Frankfurt")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE006" , "Essen")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE007" , "Stuttgart")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE008" , "Leipzig")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE009" , "Dresden")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE010" , "Dortmund")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE011" , "Dusseldorf")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE012" , "Bremen")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE013" , "Hanover")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE015" , "Bochum")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE027" , "Freiburg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE033" , "Augsburg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE034" , "Bonn")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE035" , "Karlsruhe")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE501" , "Duisburg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE502" , "Mannheim")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DE507" , "Aachen")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DK001" , "Copenhagen")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "EE001" , "Tallinn")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES001" , "Madrid")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES002" , "Barcelona")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES003" , "Valencia")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES004" , "Seville")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES005" , "Zaragoza")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES006" , "Malaga")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES008" , "Palmas")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "ES019" , "Bilbao")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FI001" , "Helsinki")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR001" , "Paris")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR003" , "Lyon")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR004" , "Toulouse")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR006" , "Strasbourg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR007" , "Bordeaux")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR008" , "Nantes")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR009" , "Lille")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR010" , "Montpellier")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR013" , "Rennes")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR026" , "Grenoble")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR032" , "Toulon")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR203" , "Marseille")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR205" , "Nice")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "FR215" , "Rouen")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT001" , "Rome")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT002" , "Milan")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT003" , "Naples")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT004" , "Turin")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT005" , "Palermo")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT006" , "Genova")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT007" , "Florence")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT008" , "Bari")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT009" , "Bologna")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT010" , "Catania")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "IT011" , "Venice")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP026" , "Mito")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP030" , "Tokyo")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP031" , "Kofu")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP034" , "Nagoya")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP036" , "Numazu")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP038" , "Osaka")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP050" , "Okayama")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP051" , "Kurashiki")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP052" , "Fukuyama")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP053" , "Hiroshima")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "JP054" , "Takamatsu")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "MEX19" , "Monterrey")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "MEX38" , "Irapuato")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "NL001" , "Hague")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "NL002" , "Amsterdam")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "NL003" , "Rotterdam")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "NL004" , "Utrecht")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "NO001" , "Oslo")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "PT001" , "Lisbon")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "PT002" , "Porto")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "SE001" , "Stockholm")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "SE002" , "Gothenburg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "SE003" , "Malmo")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US003" , "Seattle")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US012" , "Portland")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US014" , "Minneapolis")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US033" , "Milwaukee")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US035" , "Madison")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US038" , "Buffalo")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US044" , "Albany")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US045" , "Detroit")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US048" , "Boston")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US055" , "Chicago")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US060" , "Providence")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US065" , "Toledo")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US069" , "Cleveland")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US077" , "Omaha")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US081" , "Akron")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US097" , "Pittsburgh")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US103" , "Harrisburg")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US106" , "Philadelphia")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US107" , "Columbus")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US114" , "Denver")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US115" , "Indianapolis")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US117" , "Dayton")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US122" , "Baltimore")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US124" , "Cincinnati")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US125" , "Washington")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US141" , "Louisville")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US147" , "Wichita")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US149" , "Richmond")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US155" , "Fresno")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US160" , "Nashville")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US161" , "Tulsa")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US170" , "Raleigh")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US178" , "Charlotte")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US180" , "Albuquerque")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US181" , "Memphis")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US195" , "Columbia")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US196" , "Atlanta")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US202" , "Phoenix")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US209" , "Dallas")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US213" , "Charleston")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US223" , "Tucson")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US234" , "Austin")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US237" , "Jacksonville")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US242" , "Houston")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US250" , "Orlando")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US252" , "Tampa")
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "US259" , "Miami")


# Get location info via ggmap
library(ggmap)

places <- c('Vienna', 'Graz', 'Linz', 'Brussels', 'Antwerp', 'Ghent', 'Liege', 'Berlin', 'Hamburg', 'Munich', 'Cologne', 'Frankfurt', 'Essen', 'Stuttgart', 'Leipzig', 'Dresden', 'Dortmund', 'Dusseldorf', 'Bremen', 'Hanover', 'Bochum', 'Freiburg', 'Augsburg', 'Bonn', 'Karlsruhe', 'Duisburg', 'Mannheim', 'Aachen', 'Copenhagen', 'Tallinn', 'Madrid', 'Barcelona', 'Valencia', 'Seville', 'Zaragoza', 'Malaga', 'Palmas', 'Bilbao', 'Helsinki', 'Paris', 'Lyon', 'Toulouse', 'Strasbourg', 'Bordeaux', 'Nantes', 'Lille', 'Montpellier', 'Rennes', 'Grenoble', 'Toulon', 'Marseille', 'Nice', 'Rouen', 'Rome', 'Milan', 'Naples', 'Turin', 'Palermo', 'Genova', 'Florence', 'Bari', 'Bologna', 'Catania', 'Venice', 'Mito', 'Tokyo', 'Kofu', 'Nagoya', 'Numazu', 'Osaka', 'Okayama', 'Kurashiki', 'Fukuyama', 'Hiroshima', 'Takamatsu', 'Monterrey', 'Irapuato', 'Hague', 'Amsterdam', 'Rotterdam', 'Utrecht', 'Eindhoven', 'Oslo', 'Lisbon', 'Porto', 'Stockholm', 'Gothenburg', 'Malmo', 'Seattle', 'Portland', 'Minneapolis', 'Milwaukee', 'Madison', 'Buffalo', 'Albany', 'Detroit', 'Boston', 'Chicago', 'Providence', 'Toledo', 'Cleveland', 'Omaha', 'Akron', 'Pittsburgh', 'Harrisburg', 'Philadelphia', 'Columbus', 'Denver', 'Indianapolis', 'Dayton', 'Baltimore', 'Cincinnati', 'Washington', 'Louisville', 'Wichita', 'Richmond', 'Fresno', 'Nashville', 'Tulsa', 'Raleigh', 'Charlotte', 'Albuquerque', 'Memphis', 'Columbia', 'Atlanta', 'Phoenix', 'Dallas', 'Charleston', 'Tucson', 'Austin', 'Jacksonville', 'Houston', 'Orlando', 'Tampa', 'Miami')

location <- geocode(places)

location2 <- data.frame(location, places)

colnames(location2) <- c("lon" , "lat" , "METRO_ID")

# Merge OECD with locations data
oecd2 <- merge(oecd , location2 , by=c("METRO_ID")) 

```

```{r}
# Load GitHub API data

library(httr)
library(dplyr)
library(rjson)


# Pull user numbers of all GitHub users

# Create locations vector
locations <- c('Vienna', 'Graz', 'Linz', 'Brussels', 'Antwerp', 'Ghent', 'Liege', 'Berlin', 'Hamburg', 'Munich', 'Cologne', 'Frankfurt', 'Essen', 'Stuttgart', 'Leipzig', 'Dresden', 'Dortmund', 'Dusseldorf', 'Bremen', 'Hanover', 'Bochum', 'Freiburg', 'Augsburg', 'Bonn', 'Karlsruhe', 'Duisburg', 'Mannheim', 'Aachen', 'Copenhagen', 'Tallinn', 'Madrid', 'Barcelona', 'Valencia', 'Seville', 'Zaragoza', 'Malaga', 'Palmas', 'Bilbao', 'Helsinki', 'Paris', 'Lyon', 'Toulouse', 'Strasbourg', 'Bordeaux', 'Nantes', 'Lille', 'Montpellier', 'Rennes', 'Grenoble', 'Toulon', 'Marseille', 'Nice', 'Rouen', 'Rome', 'Milan', 'Naples', 'Turin', 'Palermo', 'Genova', 'Florence', 'Bari', 'Bologna', 'Catania', 'Venice', 'Mito', 'Tokyo', 'Kofu', 'Nagoya', 'Numazu', 'Osaka', 'Okayama', 'Kurashiki', 'Fukuyama', 'Hiroshima', 'Takamatsu', 'Monterrey', 'Irapuato', 'Hague', 'Amsterdam', 'Rotterdam', 'Utrecht', 'Eindhoven', 'Oslo', 'Lisbon', 'Porto', 'Stockholm', 'Gothenburg', 'Malmo', 'Seattle', 'Portland', 'Minneapolis', 'Milwaukee', 'Madison', 'Buffalo', 'Albany', 'Detroit', 'Boston', 'Chicago', 'Providence', 'Toledo', 'Cleveland', 'Omaha', 'Akron', 'Pittsburgh', 'Harrisburg', 'Philadelphia', 'Columbus', 'Denver', 'Indianapolis', 'Dayton', 'Baltimore', 'Cincinnati', 'Washington', 'Louisville',  'Wichita', 'Richmond', 'Fresno', 'Nashville', 'Tulsa', 'Raleigh', 'Charlotte', 'Albuquerque', 'Memphis', 'Columbia', 'Atlanta', 'Phoenix',  'Dallas', 'Charleston', 'Tucson', 'Austin', 'Jacksonville', 'Houston', 'Orlando', 'Tampa', 'Miami')

# Create empty vector for user counts
user_counts0 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp0 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E0')
  users0 <- GET(URL_temp0) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp0 <- users0$total_count
  
  # Add to user_counts vector
  user_counts0 <- c(user_counts0, user_counts_temp0)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts0 <- data.frame(locations, user_counts0)

# Clean API data
colnames(location_counts0) <- c("METRO_ID" , "zeroFollowers") # Rename columns


# Pull user numbers of GitHub users with over 0 followers

# Create empty vector for user counts
user_counts1 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp1 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E1')
  users1 <- GET(URL_temp1) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp1 <- users1$total_count
  
  # Add to user_counts vector
  user_counts1 <- c(user_counts1, user_counts_temp1)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts1 <- data.frame(locations, user_counts1)

# Clean API data
colnames(location_counts1) <- c("METRO_ID" , "oneFollowers") # Rename columns


# Pull user numbers of GitHub users with over 10 followers

# Create empty vector for user counts
user_counts2 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp2 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E10')
  users2 <- GET(URL_temp2) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp2 <- users2$total_count
  
  # Add to user_counts vector
  user_counts2 <- c(user_counts2, user_counts_temp2)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts2 <- data.frame(locations, user_counts2)

# Clean API data
colnames(location_counts2) <- c("METRO_ID" , "tenFollowers")


# Pull user numbers of GitHub users with over 20 followers

# Create empty vector for user counts
user_counts3 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp3 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E20')
  users3 <- GET(URL_temp3) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp3 <- users3$total_count
  
  # Add to user_counts vector
  user_counts3 <- c(user_counts3, user_counts_temp3)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts3 <- data.frame(locations, user_counts3)

# Clean API data
colnames(location_counts3) <- c("METRO_ID" , "twentyFollowers")


# Pull user numbers of GitHub users with over 30 followers

# Create empty vector for user counts
user_counts4 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp4 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E30')
  users4 <- GET(URL_temp4) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp4 <- users4$total_count
  
  # Add to user_counts vector
  user_counts4 <- c(user_counts4, user_counts_temp4)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts4 <- data.frame(locations, user_counts4)

# Clean API data
colnames(location_counts4) <- c("METRO_ID" , "thirtyFollowers")


# Pull user numbers of GitHub users with over 40 followers

# Create empty vector for user counts
user_counts5 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp5 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E40')
  users5 <- GET(URL_temp5) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp5 <- users5$total_count
  
  # Add to user_counts vector
  user_counts5 <- c(user_counts5, user_counts_temp5)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts5 <- data.frame(locations, user_counts5)

# Clean API data
colnames(location_counts5) <- c("METRO_ID" , "fortyFollowers")


# Pull user numbers of GitHub users with more than 50 followers

# Create empty vector for user counts
user_counts6 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp6 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E50')
  users6 <- GET(URL_temp6) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp6 <- users6$total_count
  
  # Add to user_counts vector
  user_counts6 <- c(user_counts6, user_counts_temp6)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts6 <- data.frame(locations, user_counts6)

# Clean API data
colnames(location_counts6) <- c("METRO_ID" , "fiftyFollowers") # Rename columns


# Pull user numbers of GitHub users with over 60 followers

# Create empty vector for user counts
user_counts7 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp7 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E60')
  users7 <- GET(URL_temp7) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp7 <- users7$total_count
  
  # Add to user_counts vector
  user_counts7 <- c(user_counts7, user_counts_temp7)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts7 <- data.frame(locations, user_counts7)

# Clean API data
colnames(location_counts7) <- c("METRO_ID" , "sixtyFollowers") # Rename columns


# Pull user numbers of GitHub users with over 70 followers

# Create empty vector for user counts
user_counts8 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp8 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E70')
  users8 <- GET(URL_temp8) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp8 <- users8$total_count
  
  # Add to user_counts vector
  user_counts8 <- c(user_counts8, user_counts_temp8)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts8 <- data.frame(locations, user_counts8)

# Clean API data
colnames(location_counts8) <- c("METRO_ID" , "seventyFollowers")


# Pull user numbers of GitHub users with over 80 followers

# Create empty vector for user counts
user_counts9 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp9 <- paste0('https://api.github.com/search/users?q=location:', i,
                      '+followers:%3E80')
  users9 <- GET(URL_temp9) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp9 <- users9$total_count
  
  # Add to user_counts vector
  user_counts9 <- c(user_counts9, user_counts_temp9)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts9 <- data.frame(locations, user_counts9)

# Clean API data
colnames(location_counts9) <- c("METRO_ID" , "eightyFollowers")


# Pull user numbers of GitHub users with over 90 followers

# Create empty vector for user counts
user_counts10 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp10 <- paste0('https://api.github.com/search/users?q=location:', i,
                       '+followers:%3E90')
  users10 <- GET(URL_temp10) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp10 <- users10$total_count
  
  # Add to user_counts vector
  user_counts10 <- c(user_counts10, user_counts_temp10)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts10 <- data.frame(locations, user_counts10)

# Clean API data
colnames(location_counts10) <- c("METRO_ID" , "ninetyFollowers")


# Pull user numbers of GitHub users with over 100 followers

# Create empty vector for user counts
user_counts11 <- vector()

# Loop through the locations and download the user counts
## Note: the %23E turns into a greater than sign >
for (i in locations){
  # Download raw data
  URL_temp11 <- paste0('https://api.github.com/search/users?q=location:', i,
                       '+followers:%3E100')
  users11 <- GET(URL_temp11) %>% 
    content(as = 'text') %>% 
    fromJSON()               
  
  # Extract counts of users that meet criteria for the location
  user_counts_temp11 <- users11$total_count
  
  # Add to user_counts vector
  user_counts11 <- c(user_counts11, user_counts_temp11)
  
  # Sleep R for 7 seconds so you don't overload the API
  Sys.sleep(7); message('-')
}

# Combine locations and user counts data
location_counts11 <- data.frame(locations, user_counts11)

# Clean API data
colnames(location_counts11) <- c("METRO_ID" , "hundredFollowers")


# Merge different follower number dataframes
location_countsA <- merge(location_counts0 , location_counts1 , by=c("METRO_ID"))
location_countsB <- merge(location_countsA , location_counts2 , by=c("METRO_ID"))
location_countsC <- merge(location_countsB , location_counts3 , by=c("METRO_ID"))
location_countsD <- merge(location_countsC , location_counts4 , by=c("METRO_ID"))
location_countsE <- merge(location_countsD , location_counts5 , by=c("METRO_ID"))
location_countsF <- merge(location_counts6 , location_counts7 , by=c("METRO_ID"))
location_countsG <- merge(location_countsF , location_counts8 , by=c("METRO_ID"))
location_countsH <- merge(location_countsG , location_counts9 , by=c("METRO_ID"))
location_countsI <- merge(location_countsH , location_counts10 , by=c("METRO_ID"))
api <- merge(location_countsI , location_counts11 , by=c("METRO_ID"))

```

```{r}
# Merge all datasets

dataset <- merge(oecd2 , api , by=c("METRO_ID"))

```

```{r}
# Clean dataset for analysis

# Make new variable with over 20 followers per 10,000 population
over20 <- subset(dataset, select = c("METRO_ID","twentyFollowers"))
colnames(over20) <- c("METRO_ID" , "hifol")

dataset <- merge(dataset , over20 , by=c("METRO_ID"))

# Change total counts into counts per population
dataset$zeroFollowers <- dataset$zeroFollowers/dataset$Population
dataset$zeroFollowers <- dataset$zeroFollowers*10000

dataset$oneFollowers <- dataset$oneFollowers/dataset$Population
dataset$oneFollowers <- dataset$oneFollowers*10000

dataset$tenFollowers <- dataset$tenFollowers/dataset$Population
dataset$tenFollowers <- dataset$tenFollowers*10000

dataset$twentyFollowers <- dataset$twentyFollowers/dataset$Population
dataset$twentyFollowers <- dataset$twentyFollowers*10000

dataset$thirtyFollowers <- dataset$thirtyFollowers/dataset$Population
dataset$thirtyFollowers <- dataset$thirtyFollowers*10000

dataset$fortyFollowers <- dataset$fortyFollowers/dataset$Population
dataset$fortyFollowers <- dataset$fortyFollowers*10000

dataset$fiftyFollowers <- dataset$fiftyFollowers/dataset$Population
dataset$fiftyFollowers <- dataset$fiftyFollowers*10000

dataset$sixtyFollowers <- dataset$sixtyFollowers/dataset$Population
dataset$sixtyFollowers <- dataset$sixtyFollowers*10000

dataset$seventyFollowers <- dataset$seventyFollowers/dataset$Population
dataset$seventyFollowers <- dataset$seventyFollowers*10000

dataset$eightyFollowers <- dataset$eightyFollowers/dataset$Population
dataset$eightyFollowers <- dataset$eightyFollowers*10000

dataset$ninetyFollowers <- dataset$ninetyFollowers/dataset$Population
dataset$ninetyFollowers <- dataset$ninetyFollowers*10000

dataset$hundredFollowers <- dataset$hundredFollowers/dataset$Population
dataset$hundredFollowers <- dataset$hundredFollowers*10000

dataset$hifol <- dataset$hifol/dataset$Population
dataset$hifol <- dataset$hifol*10000


# Change follower numbers into categories
dataset$oneFollowers <- dataset$zeroFollowers-dataset$tenFollowers # 1-9 followers
dataset$tenFollowers <- dataset$tenFollowers-dataset$twentyFollowers # 10-19 followers
dataset$twentyFollowers <- dataset$twentyFollowers-dataset$thirtyFollowers # 20-29 followers
dataset$thirtyFollowers <- dataset$thirtyFollowers-dataset$fortyFollowers # 30-39 followers
dataset$fortyFollowers <- dataset$fortyFollowers-dataset$fiftyFollowers # 40-49 followers
dataset$fiftyFollowers <- dataset$fiftyFollowers-dataset$sixtyFollowers # 50-59 followers
dataset$sixtyFollowers <- dataset$sixtyFollowers-dataset$seventyFollowers # 60-69 followers
dataset$seventyFollowers <- dataset$seventyFollowers-dataset$eightyFollowers # 70-79 followers
dataset$eightyFollowers <- dataset$eightyFollowers-dataset$ninetyFollowers # 80-89 followers
dataset$ninetyFollowers <- dataset$ninetyFollowers-dataset$hundredFollowers # 90-99 followers

# Rename columns
colnames(dataset) <- c("METRO_ID" , "Patents" , "GDP" , "Population", "Greenspace", "Employment" , "Pollution" , "lon" , "lat" , "Followers" , "1" , "10" , "20" , "30" , "40" , "50" , "60" , "70" , "80" , "90" , "100" , "US" , "DE" , "FR" , "JP" , "hifol")


```


```{r}
# Save as .csv
write.csv(dataset, file = "dataset.csv")
```

